{
  "cells": [
    {
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true
      },
      "cell_type": "code",
      "source": "%matplotlib inline",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "trusted": true
      },
      "cell_type": "code",
      "source": "#General python packages\nfrom typing import List,Optional,Tuple,Union\nimport logging\nfrom functools import partial\nimport pandas as pd\nimport numpy as np\nimport os\nfrom PIL import Image\nfrom matplotlib import pyplot as plt\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.model_selection import train_test_split\nimport time\nimport copy",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "07fda4a868186a05a787e8f32f1d199058211183"
      },
      "cell_type": "code",
      "source": "#Pytorch packages.\nimport torch\nimport torch.nn as nn\nfrom torch.optim import Adam\nfrom torchvision.models.resnet import BasicBlock\nfrom torch.utils.data import DataLoader\nfrom torch.utils.data import Dataset\nfrom torchvision.models.resnet import ResNet\nfrom torch import Tensor\nfrom torchvision import transforms\nfrom torch.autograd import Variable",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "7463d3ddc13125162269853ddd52f101032f6421"
      },
      "cell_type": "code",
      "source": "# Path locations of image data.\nDATA_FOLDER = '../input'\nLABELS = f'{DATA_FOLDER}/train_labels.csv'\nTRAIN_IMAGES_FOLDER = f'{DATA_FOLDER}/train'\nTEST_IMAGES_FOLDER = f'{DATA_FOLDER}/test'\nUSE_GPU = torch.cuda.is_available()\ncuda = torch.device('cuda') ",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "a65ccc7a4d94d1231d732e428ef1489bf921b254"
      },
      "cell_type": "code",
      "source": "## Reading label file to know the structure.\ntrain_labels=pd.read_csv(LABELS)\ntrain_labels.head()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "4c19381bc2fe1f2ff37f0a5b734b331770ca67b6"
      },
      "cell_type": "code",
      "source": "# train valid split\ntrain_x,valid_x,train_y,valid_y=train_test_split(train_labels['id'],train_labels['label'],\n                             test_size=0.2,shuffle=True,\n                             random_state=9,stratify=train_labels['label'])\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "bb926fe09d52366d5ab8b5b2b32c9ebc8d6ead77"
      },
      "cell_type": "code",
      "source": "print('train x : ',train_x.shape)\nprint('train y : ',train_y.shape)\n\nprint('valid x : ',valid_x.shape)\nprint('valid y : ',valid_y.shape)\nprint('type : ',type(valid_x))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "dbe3049ea7b7867fb00408bf61c9c3791d37274f"
      },
      "cell_type": "code",
      "source": "train_y,valid_y=train_y.values.reshape(-1,1),valid_y.values.reshape(-1,1)\ntrain_x=[os.path.join(TRAIN_IMAGES_FOLDER, f'{f}.tif') for f in train_x.values]\nvalid_x=[os.path.join(TRAIN_IMAGES_FOLDER, f'{f}.tif') for f in valid_x.values]",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "eb3732767ffbf4664691ef350654c0411ec9c632"
      },
      "cell_type": "code",
      "source": "def pil2tensor(image,dtype:np.dtype):\n    \"Convert PIL style `image` array to torch style image tensor.\"\n    a = np.asarray(image)\n    if a.ndim==2 : a = np.expand_dims(a,2)\n    a = np.transpose(a, (1, 0, 2))\n    a = np.transpose(a, (2, 1, 0))\n    return torch.from_numpy(a.astype(dtype, copy=False) )",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "d9e5266f4e60e95ac1c71a4e6e845917f82aa8b9"
      },
      "cell_type": "code",
      "source": "# Dataloading in pytorch is done by inheriting Dataset class , \n#Defining methods to create Dataset Objects\nclass ImageDataset(Dataset):\n    def __init__(self,ImagePaths:List):\n        self.ImagePaths=ImagePaths\n    def __len__(self) -> int:\n        return len(self.ImagePaths)\n    def __getitem__(self,index:int) ->Image.Image:\n        img=Image.open(self.ImagePaths[index])\n        return pil2tensor(img,np.float32)\n# Similarly creating for labels\nclass LabelDataset(Dataset):\n    def __init__(self,labels:List):\n        self.labels=labels\n    def __len__(self) -> int:\n        return len(self.labels)\n    def __getitem__(self,index:int):\n        return self.labels[index]\n    \n#Combining inputs and labels in a single pytorch Dataset for enabling dataloaders.\nclass VisionDataset(Dataset):\n    def __init__(self,x:Dataset,y:Dataset):\n        self.x=x\n        self.y=y\n    def __len__(self) ->int:\n        return self.x.__len__()\n    def __getitem__(self,index:int) ->Tuple:\n        return (self.x[index],self.y[index])\n    ",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "2175daddce868ccf7ea6851a4e29ff0e03cab7cc"
      },
      "cell_type": "code",
      "source": "# Creating Pytorch Datasets from Data\ntrain_dataset = VisionDataset(ImageDataset(train_x), LabelDataset(train_y))\nvalid_dataset = VisionDataset(ImageDataset(valid_x), LabelDataset(valid_y))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "61f08f2a4462ea237b2b9d492a40640e2ba86af7"
      },
      "cell_type": "code",
      "source": "# Creating Dataloaders for the Datasets to enable batch wise training\nshuffle = True\nbatch_size = 256\nnum_workers = 0\ntrain_dataloader = DataLoader(train_dataset, \n                              batch_size=batch_size, \n                              shuffle=shuffle, \n                              num_workers=num_workers)\nvalid_dataloader = DataLoader(valid_dataset, \n                              batch_size=batch_size, \n                              shuffle=False, \n                              num_workers=num_workers)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "134dc1abcb646a406daf360aa240850f55616232"
      },
      "cell_type": "code",
      "source": "#Model Architecture to be used.\ndef resnet9(output_dim:int=1) ->nn.Module:\n    model = ResNet(BasicBlock, [1, 1, 1, 1])\n    in_features = model.fc.in_features\n    model.avgpool=nn.AdaptiveAvgPool2d(1)\n    model.fc=nn.Linear(in_features,output_dim)\n    return model.to(cuda) if USE_GPU else model",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "d01cb96abfd69103b17cf327b8dc0120adfa0433"
      },
      "cell_type": "code",
      "source": "resnet_basic=resnet9(output_dim=2)\nresnet_basic",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "5d878b8632c2f88ecba766bb811997266b592a3a"
      },
      "cell_type": "code",
      "source": "# Defining optimization and loss criteria\nlr = 1e-3\noptimizer = Adam(resnet_basic.parameters(), lr=lr)\ncriterion = nn.CrossEntropyLoss()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "98abb3ac6d73d56fcf42e9f753444ff5a502bd5c"
      },
      "cell_type": "code",
      "source": "def T(tensor):\n    if not torch.is_tensor(tensor):\n        tensor = torch.FloatTensor(tensor)\n    else:\n        tensor = tensor.type(torch.FloatTensor)\n    return tensor",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "068f9dbbd2ede5a032c09646955fec753e0f9a7d"
      },
      "cell_type": "code",
      "source": "# train function for training the network\ndef train_model(model,dataloaders,criterion,optimizer,num_epochs=1):\n    since=time.time()\n    val_acc_history = []\n    best_model_wts = copy.deepcopy(model.state_dict())\n    best_acc = 0.0\n    for epoch in range(num_epochs):\n        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n        print('-' * 10)\n        for phase in ['train','val']:\n            if phase=='train':\n                model=model.train()\n            else:\n                model=model.eval()\n            running_loss=0.0\n            running_corrects=0\n            for inputs,labels in dataloaders[phase]:\n                inputs,labels=T(inputs).to(cuda),T(labels).to(cuda)\n                optimizer.zero_grad()\n                with torch.set_grad_enabled(phase == 'train'):\n                    outputs=model(inputs)\n                    loss = criterion(outputs, labels.squeeze(1).long())\n                    _,preds=torch.max(outputs,1)\n                    running_loss+=loss.item()*inputs.size(0)\n                    running_corrects=running_corrects+torch.sum(preds==labels.squeeze(1).long())\n                    if phase=='train':\n                        loss=loss.backward()\n                        optimizer.step()\n            epoch_loss=running_loss/len(dataloaders[phase].dataset)\n            epoch_acc=running_corrects.double()/len(dataloaders[phase].dataset)\n            print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n            # deep copy the model\n            if phase == 'val' and epoch_acc > best_acc:\n                best_acc = epoch_acc\n                best_model_wts = copy.deepcopy(model.state_dict())\n            if phase == 'val':\n                val_acc_history.append(epoch_acc)\n        print()\n    time_elapsed = time.time() - since\n    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n    print('Best val Acc: {:4f}'.format(best_acc))\n    # load best model weights\n    model.load_state_dict(best_model_wts)\n    return model, val_acc_history",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "28cd7d7b68d7586038654c78b5ff9973ca73ac64"
      },
      "cell_type": "code",
      "source": "num_epochs=12\ndataloaders_dict={'train':train_dataloader,'val':valid_dataloader}",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "fd6694962a7627402d8bc4f92293e750836dc166"
      },
      "cell_type": "code",
      "source": "model_ft, hist = train_model(resnet_basic, dataloaders_dict, criterion, optimizer,\n                             num_epochs=num_epochs)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "46823940e831d1d879a1ba1936e99a7e8d14ef81"
      },
      "cell_type": "code",
      "source": "#Creating Test dataset and then Dataloader for predicting\ntest_x=[os.path.join(TEST_IMAGES_FOLDER, f'{f}') for f in \n        os.listdir(TEST_IMAGES_FOLDER)]\ntest_dataset=ImageDataset(test_x)\ntest_dataloader = DataLoader(test_dataset, \n                              batch_size=batch_size, \n                              shuffle=False, \n                              num_workers=num_workers)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "ba481400de521fd315a6c33f9a0158e7775b24f7"
      },
      "cell_type": "code",
      "source": "def predictions(model:nn.Module,test_dataloader:DataLoader):\n    total_preds=[]\n    for x in test_dataloader:\n        out=model(T(x).to(cuda))\n        _,preds=torch.max(out,1)\n        total_preds.append(preds)\n    return torch.cat(total_preds).cpu().numpy()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "75c4b7b3fe473669eeaa35117c891cb6e9be641d"
      },
      "cell_type": "code",
      "source": "predicts=predictions(model_ft,test_dataloader)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "2c5a24303a47e2cd6ae478719ff22734e60dc058"
      },
      "cell_type": "code",
      "source": "testfilenames=[os.path.basename(f).split('.')[0] for f in test_x]\nsubmission=pd.DataFrame({'id':testfilenames,'label':predicts})\n#submission.to_csv('submission.csv',row.names=False)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "4a8d23627f93d6df6ab1b8dc6314ff7252b17b87"
      },
      "cell_type": "code",
      "source": "submission.to_csv('submission.csv',index=False)",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.6",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}