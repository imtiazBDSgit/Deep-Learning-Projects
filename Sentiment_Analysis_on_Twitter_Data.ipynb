{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Sentiment Analysis on Twitter Data.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/imtiazBDSgit/Deep-Learning-Projects/blob/master/Sentiment_Analysis_on_Twitter_Data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JSRl4XtCiffJ",
        "colab_type": "text"
      },
      "source": [
        "# Sentiment Analysis on Twitter Reviews\n",
        "In this notebook, we show how transfer learning can be applied to detecting the sentiment of twitter reviews, between positive and negative reviews.\n",
        "\n",
        "This notebook uses the work from [Howard and Ruder, Ulmfit](https://arxiv.org/pdf/1801.06146.pdf).\n",
        "The idea of the paper (and it implementation explained in the [fast.ai deep learning course](http://course.fast.ai/lessons/lesson10.html)) is to learn a language model trained on a very large dataset, e.g. a Wikipedia dump. The intuition is that if a model is able to predict the next word at each word, it means it has learnt something about the structure of the language we are using."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aRu2u070IbVA",
        "colab_type": "text"
      },
      "source": [
        "# New Section"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o1gSu3G_iffM",
        "colab_type": "text"
      },
      "source": [
        "# Content of this notebook"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PrZ5W8m9iffP",
        "colab_type": "text"
      },
      "source": [
        "The notebook is organized as such:\n",
        "\n",
        "- Tokenize the reviews and create dictionaries\n",
        "- Download a pre-trained model and link the dictionary to the embedding layer of the model\n",
        "- Fine-tune the language model on the twitter reviews texts\n",
        "\n",
        "We have then the backbone of our algorithm: a pre-trained language model fine-tuned on twitter reviews\n",
        "\n",
        "- Add a classifier to the language model and train the classifier layer only\n",
        "- Gradually defreeze successive layers to train different layers on the twitter reviews\n",
        "- Run a full classification task for several epochs\n",
        "- Use the model for inference!\n",
        "\n",
        "We end this notebook by looking at the specific effect of training size on the overall performance. This is to test the hypothesis that the ULMFit model does not need much labeled data to perform well."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "41if5jpWiffR",
        "colab_type": "text"
      },
      "source": [
        "# Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GdeymwL-iffU",
        "colab_type": "text"
      },
      "source": [
        "Before starting, you should upload the data from folder somewhere you like, and use this path for this notebook.\n",
        "\n",
        "Also, recommended working on a dedicated environment (e.g. mkvirtualenv fastai). Then clone the fastai github repo https://github.com/fastai/fastai and install requirements."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mtOh2d1biffV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from fastai.text import *\n",
        "import html\n",
        "import os\n",
        "import pandas as pd\n",
        "import pickle\n",
        "import re\n",
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, classification_report, \\\n",
        "confusion_matrix\n",
        "from sklearn.model_selection import train_test_split\n",
        "from time import time"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rGArIEgpiffa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "path = '/content/sample_data/'\n",
        "data=pd.read_csv(path+'Data.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "soriWa2vGpA8",
        "colab_type": "code",
        "outputId": "ae20db7c-ce0d-4d3c-b1d2-76b94facb85d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        }
      },
      "source": [
        "data[['text','sentiment']].head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>What @dhepburn said.</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>plus you've added commercials to the experienc...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>I didn't today... Must mean I need to take ano...</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>it's really aggressive to blast obnoxious \"ent...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>and it's a really big bad thing about it</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text sentiment\n",
              "0                               What @dhepburn said.   neutral\n",
              "1  plus you've added commercials to the experienc...  positive\n",
              "2  I didn't today... Must mean I need to take ano...   neutral\n",
              "3  it's really aggressive to blast obnoxious \"ent...  negative\n",
              "4           and it's a really big bad thing about it  negative"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 103
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GXbx2XNKiffe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train, test, train_label, test_label = train_test_split( data['text'], data['sentiment'],\n",
        "                                                        test_size=0.20, random_state=42,stratify=data['sentiment'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-IuXNXN3H40q",
        "colab_type": "code",
        "outputId": "900f3ed7-77fb-41e4-e840-2441de2fef27",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "print(\"train shape\",train.shape)\n",
        "print(\"validation shape\",test.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train shape (11712,)\n",
            "validation shape (2928,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5kDRNyQbIS78",
        "colab_type": "code",
        "outputId": "fe8fc696-2261-4c02-b40e-913ffee0030e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "source": [
        "print(\"train sentiment distribution\")\n",
        "train_label.value_counts(normalize=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train sentiment distribution\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "negative    0.626878\n",
              "neutral     0.211663\n",
              "positive    0.161458\n",
              "Name: sentiment, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 106
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6hzEKNAxIg5l",
        "colab_type": "code",
        "outputId": "450bd50d-55e4-4fda-dc33-24001bc55a12",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "source": [
        "print(\"valid sentiment distribution\")\n",
        "test_label.value_counts(normalize=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "valid sentiment distribution\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "negative    0.627049\n",
              "neutral     0.211749\n",
              "positive    0.161202\n",
              "Name: sentiment, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 107
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zrTmBrBlk-2u",
        "colab_type": "code",
        "outputId": "d17ada6e-315f-4e85-91d5-83e2c2499b56",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "valid_index=test.index\n",
        "valid_index"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Int64Index([ 4839,  7719, 13337,  3764,  5657,  2973,   336, 10504,  2923,\n",
              "            11763,\n",
              "            ...\n",
              "             8627, 10487, 12100,   712,  9732, 10313,  2099, 10317,  8658,\n",
              "            14210],\n",
              "           dtype='int64', length=2928)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 109
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mFkN6M2TlExh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data['is_valid']=[True if x in valid_index else False for x in data.index]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p-ZyZwmplbjR",
        "colab_type": "code",
        "outputId": "39e09707-b325-4ade-bdea-6bce8cad4789",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        }
      },
      "source": [
        "data_prep=data[['sentiment','text','is_valid']]\n",
        "data_prep.columns=['label','text','is_valid']\n",
        "data_prep.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>text</th>\n",
              "      <th>is_valid</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>neutral</td>\n",
              "      <td>What @dhepburn said.</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>positive</td>\n",
              "      <td>plus you've added commercials to the experienc...</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>neutral</td>\n",
              "      <td>I didn't today... Must mean I need to take ano...</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>negative</td>\n",
              "      <td>it's really aggressive to blast obnoxious \"ent...</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>negative</td>\n",
              "      <td>and it's a really big bad thing about it</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      label                                               text  is_valid\n",
              "0   neutral                               What @dhepburn said.     False\n",
              "1  positive  plus you've added commercials to the experienc...     False\n",
              "2   neutral  I didn't today... Must mean I need to take ano...     False\n",
              "3  negative  it's really aggressive to blast obnoxious \"ent...     False\n",
              "4  negative           and it's a really big bad thing about it      True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 111
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "4ee55e4c-8c48-42a1-fac7-3fc5b75a96ee",
        "id": "03oZSO-EklQX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        }
      },
      "source": [
        "# Language model data\n",
        "data_lm = TextLMDataBunch.from_df(PATH,data_prep[data_prep.is_valid==False],data_prep[data_prep.is_valid==True])\n",
        "# Classifier model data\n",
        "data_clas = TextClasDataBunch.from_df(PATH,data_prep[data_prep.is_valid==False],data_prep[data_prep.is_valid==True], vocab=data_lm.train_ds.vocab, bs=32,text_cols=['text'])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "peRmmfA2bMhr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_lm.save('data_lm_export.pkl')\n",
        "data_clas.save('data_clas_export.pkl')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tJysO9zIhsqw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_lm = load_data(PATH,'data_lm_export.pkl')\n",
        "data_clas = load_data(PATH,'data_clas_export.pkl', bs=32)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bUhowRxzhoox",
        "colab_type": "code",
        "outputId": "17aa3b07-cac9-4378-8c7a-2d9ed187a9eb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 79
        }
      },
      "source": [
        "learn = language_model_learner(data_lm, AWD_LSTM, drop_mult=0.5)\n",
        "learn.fit_one_cycle(1, 1e-2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>4.769918</td>\n",
              "      <td>4.180489</td>\n",
              "      <td>0.243359</td>\n",
              "      <td>12:20</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TS0ZjK_JifhL",
        "colab_type": "code",
        "outputId": "4eb861ae-6ffd-43ec-cb5a-b40cb9fc956f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 79
        }
      },
      "source": [
        "# Run one epoch of fine-tuning \n",
        "learn.unfreeze()\n",
        "learn.fit_one_cycle(1, 1e-3)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>4.077415</td>\n",
              "      <td>3.933756</td>\n",
              "      <td>0.278181</td>\n",
              "      <td>13:30</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4V3XhAukifhc",
        "colab_type": "code",
        "outputId": "b05f4e23-5a22-4612-a6fb-5c5eb6021c7c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "learn.predict(\"and it's a really big\", n_words=10)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"and it's a really big deal ! ! No help i m supposed to\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 117
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wIg3UP9jnpYq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learn.save_encoder('ft_enc')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zGJ9fV_Difhf",
        "colab_type": "text"
      },
      "source": [
        "# Going back to classification!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "svJCQQ-sifhg",
        "colab_type": "text"
      },
      "source": [
        "Now that we spent some time fine-tuning the language model on our twitter data, let's see if we can classify easily these reviews.\n",
        "As before, some cells should be run once, and then use data loaders for later use."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XWWxZVJyifiO",
        "colab_type": "code",
        "outputId": "aff34e87-7f6b-4365-a942-07d368cc052d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "learn = text_classifier_learner(data_clas, AWD_LSTM, drop_mult=0.5)\n",
        "learn.load_encoder('ft_enc')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RNNLearner(data=TextClasDataBunch;\n",
              "\n",
              "Train: LabelList (11712 items)\n",
              "x: TextList\n",
              "xxbos xxmaj what xxunk said .,xxbos plus you 've added commercials to the experience ... xxunk .,xxbos i did n't today ... xxmaj must mean i need to take another trip !,xxbos it 's really aggressive to blast obnoxious \" entertainment \" in your guests ' faces & & they have little recourse,xxbos yes , nearly every time i fly xxup vx this _ _ ar xxunk _ won _ _ go away :)\n",
              "y: CategoryList\n",
              "neutral,positive,neutral,negative,positive\n",
              "Path: /content/sample_data;\n",
              "\n",
              "Valid: LabelList (2928 items)\n",
              "x: TextList\n",
              "xxbos and it 's a really big bad thing about it,xxbos seriously would pay $ 30 a flight for seats that did n't have this playing . \n",
              "  it 's really the only bad thing about flying xxup va,xxbos xxmaj really missed a prime opportunity for xxmaj xxunk xxmaj without xxmaj xxunk xxunk , there . https : / / t.co / xxunk,xxbos xxmaj well , i xxunk xxup now i xxup do ! xxup xxunk,xxbos xxunk i 'm flying your # fabulous # xxmaj xxunk skies again ! u take all the # stress away from travel http : / / t.co / xxunk\n",
              "y: CategoryList\n",
              "negative,negative,neutral,positive,positive\n",
              "Path: /content/sample_data;\n",
              "\n",
              "Test: None, model=SequentialRNN(\n",
              "  (0): MultiBatchEncoder(\n",
              "    (module): AWD_LSTM(\n",
              "      (encoder): Embedding(5792, 400, padding_idx=1)\n",
              "      (encoder_dp): EmbeddingDropout(\n",
              "        (emb): Embedding(5792, 400, padding_idx=1)\n",
              "      )\n",
              "      (rnns): ModuleList(\n",
              "        (0): WeightDropout(\n",
              "          (module): LSTM(400, 1152, batch_first=True)\n",
              "        )\n",
              "        (1): WeightDropout(\n",
              "          (module): LSTM(1152, 1152, batch_first=True)\n",
              "        )\n",
              "        (2): WeightDropout(\n",
              "          (module): LSTM(1152, 400, batch_first=True)\n",
              "        )\n",
              "      )\n",
              "      (input_dp): RNNDropout()\n",
              "      (hidden_dps): ModuleList(\n",
              "        (0): RNNDropout()\n",
              "        (1): RNNDropout()\n",
              "        (2): RNNDropout()\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (1): PoolingLinearClassifier(\n",
              "    (layers): Sequential(\n",
              "      (0): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (1): Dropout(p=0.2, inplace=False)\n",
              "      (2): Linear(in_features=1200, out_features=50, bias=True)\n",
              "      (3): ReLU(inplace=True)\n",
              "      (4): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (5): Dropout(p=0.1, inplace=False)\n",
              "      (6): Linear(in_features=50, out_features=3, bias=True)\n",
              "    )\n",
              "  )\n",
              "), opt_func=functools.partial(<class 'torch.optim.adam.Adam'>, betas=(0.9, 0.99)), loss_func=FlattenedLoss of CrossEntropyLoss(), metrics=[<function accuracy at 0x7f06eadac8c8>], true_wd=True, bn_wd=True, wd=0.01, train_bn=True, path=PosixPath('/content/sample_data'), model_dir='models', callback_fns=[functools.partial(<class 'fastai.basic_train.Recorder'>, add_time=True, silent=False)], callbacks=[RNNTrainer\n",
              "learn: RNNLearner(data=TextClasDataBunch;\n",
              "\n",
              "Train: LabelList (11712 items)\n",
              "x: TextList\n",
              "xxbos xxmaj what xxunk said .,xxbos plus you 've added commercials to the experience ... xxunk .,xxbos i did n't today ... xxmaj must mean i need to take another trip !,xxbos it 's really aggressive to blast obnoxious \" entertainment \" in your guests ' faces & & they have little recourse,xxbos yes , nearly every time i fly xxup vx this _ _ ar xxunk _ won _ _ go away :)\n",
              "y: CategoryList\n",
              "neutral,positive,neutral,negative,positive\n",
              "Path: /content/sample_data;\n",
              "\n",
              "Valid: LabelList (2928 items)\n",
              "x: TextList\n",
              "xxbos and it 's a really big bad thing about it,xxbos seriously would pay $ 30 a flight for seats that did n't have this playing . \n",
              "  it 's really the only bad thing about flying xxup va,xxbos xxmaj really missed a prime opportunity for xxmaj xxunk xxmaj without xxmaj xxunk xxunk , there . https : / / t.co / xxunk,xxbos xxmaj well , i xxunk xxup now i xxup do ! xxup xxunk,xxbos xxunk i 'm flying your # fabulous # xxmaj xxunk skies again ! u take all the # stress away from travel http : / / t.co / xxunk\n",
              "y: CategoryList\n",
              "negative,negative,neutral,positive,positive\n",
              "Path: /content/sample_data;\n",
              "\n",
              "Test: None, model=SequentialRNN(\n",
              "  (0): MultiBatchEncoder(\n",
              "    (module): AWD_LSTM(\n",
              "      (encoder): Embedding(5792, 400, padding_idx=1)\n",
              "      (encoder_dp): EmbeddingDropout(\n",
              "        (emb): Embedding(5792, 400, padding_idx=1)\n",
              "      )\n",
              "      (rnns): ModuleList(\n",
              "        (0): WeightDropout(\n",
              "          (module): LSTM(400, 1152, batch_first=True)\n",
              "        )\n",
              "        (1): WeightDropout(\n",
              "          (module): LSTM(1152, 1152, batch_first=True)\n",
              "        )\n",
              "        (2): WeightDropout(\n",
              "          (module): LSTM(1152, 400, batch_first=True)\n",
              "        )\n",
              "      )\n",
              "      (input_dp): RNNDropout()\n",
              "      (hidden_dps): ModuleList(\n",
              "        (0): RNNDropout()\n",
              "        (1): RNNDropout()\n",
              "        (2): RNNDropout()\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (1): PoolingLinearClassifier(\n",
              "    (layers): Sequential(\n",
              "      (0): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (1): Dropout(p=0.2, inplace=False)\n",
              "      (2): Linear(in_features=1200, out_features=50, bias=True)\n",
              "      (3): ReLU(inplace=True)\n",
              "      (4): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (5): Dropout(p=0.1, inplace=False)\n",
              "      (6): Linear(in_features=50, out_features=3, bias=True)\n",
              "    )\n",
              "  )\n",
              "), opt_func=functools.partial(<class 'torch.optim.adam.Adam'>, betas=(0.9, 0.99)), loss_func=FlattenedLoss of CrossEntropyLoss(), metrics=[<function accuracy at 0x7f06eadac8c8>], true_wd=True, bn_wd=True, wd=0.01, train_bn=True, path=PosixPath('/content/sample_data'), model_dir='models', callback_fns=[functools.partial(<class 'fastai.basic_train.Recorder'>, add_time=True, silent=False)], callbacks=[...], layer_groups=[Sequential(\n",
              "  (0): Embedding(5792, 400, padding_idx=1)\n",
              "  (1): EmbeddingDropout(\n",
              "    (emb): Embedding(5792, 400, padding_idx=1)\n",
              "  )\n",
              "), Sequential(\n",
              "  (0): WeightDropout(\n",
              "    (module): LSTM(400, 1152, batch_first=True)\n",
              "  )\n",
              "  (1): RNNDropout()\n",
              "), Sequential(\n",
              "  (0): WeightDropout(\n",
              "    (module): LSTM(1152, 1152, batch_first=True)\n",
              "  )\n",
              "  (1): RNNDropout()\n",
              "), Sequential(\n",
              "  (0): WeightDropout(\n",
              "    (module): LSTM(1152, 400, batch_first=True)\n",
              "  )\n",
              "  (1): RNNDropout()\n",
              "), Sequential(\n",
              "  (0): PoolingLinearClassifier(\n",
              "    (layers): Sequential(\n",
              "      (0): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (1): Dropout(p=0.2, inplace=False)\n",
              "      (2): Linear(in_features=1200, out_features=50, bias=True)\n",
              "      (3): ReLU(inplace=True)\n",
              "      (4): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (5): Dropout(p=0.1, inplace=False)\n",
              "      (6): Linear(in_features=50, out_features=3, bias=True)\n",
              "    )\n",
              "  )\n",
              ")], add_time=True, silent=False)\n",
              "alpha: 2.0\n",
              "beta: 1.0], layer_groups=[Sequential(\n",
              "  (0): Embedding(5792, 400, padding_idx=1)\n",
              "  (1): EmbeddingDropout(\n",
              "    (emb): Embedding(5792, 400, padding_idx=1)\n",
              "  )\n",
              "), Sequential(\n",
              "  (0): WeightDropout(\n",
              "    (module): LSTM(400, 1152, batch_first=True)\n",
              "  )\n",
              "  (1): RNNDropout()\n",
              "), Sequential(\n",
              "  (0): WeightDropout(\n",
              "    (module): LSTM(1152, 1152, batch_first=True)\n",
              "  )\n",
              "  (1): RNNDropout()\n",
              "), Sequential(\n",
              "  (0): WeightDropout(\n",
              "    (module): LSTM(1152, 400, batch_first=True)\n",
              "  )\n",
              "  (1): RNNDropout()\n",
              "), Sequential(\n",
              "  (0): PoolingLinearClassifier(\n",
              "    (layers): Sequential(\n",
              "      (0): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (1): Dropout(p=0.2, inplace=False)\n",
              "      (2): Linear(in_features=1200, out_features=50, bias=True)\n",
              "      (3): ReLU(inplace=True)\n",
              "      (4): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (5): Dropout(p=0.1, inplace=False)\n",
              "      (6): Linear(in_features=50, out_features=3, bias=True)\n",
              "    )\n",
              "  )\n",
              ")], add_time=True, silent=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 121
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t9YpHhTlnzQ8",
        "colab_type": "code",
        "outputId": "b344e909-ee78-4ff8-9df2-500e3837411a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "source": [
        "data_clas.show_batch()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>xxbos xxmaj hi have a question re future xxmaj flight xxmaj booking xxmaj problems . xxup dub - xxup jac 29 / 9 xxup jac - xxup lax 8 / 10 xxup lax - xxup dub 13 / 10 . i 'm * xxup g. xxmaj what is checked bag allowance for xxup jac - xxup lax ?</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>xxbos i keep calling your help line ( 800 ) 428 - 4322 and it keeps saying they are too busy to help &amp; &amp; to call back xxmaj late xxmaj flightr . xxup for a xxup week xxup now !</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>xxbos xxmaj flight 830 xxup clt to xxmaj phl . i was 1st on list . xxmaj someone else got spot . xxmaj rude employee in coach . xxmaj xxunk give xxup id . xxmaj said he was cute red head</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>xxbos not happy w / app xxmaj late xxmaj flightly . xxmaj last time i flew would n't let me check in , xxmaj this time i checked in went on xxmaj late xxmaj flightr says i never checked in</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>xxbos xxmaj it 's for me , i spoke with a rep on the phone who suggested i \" xxmaj voice a concern \" via \" xxmaj email us \" on your site . i did a few moments ago</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IXBiiHX9n0H7",
        "colab_type": "code",
        "outputId": "3bd4977a-9acf-4e19-cc2c-aa401bb2b375",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 79
        }
      },
      "source": [
        "learn.fit_one_cycle(1, 1e-2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>0.685052</td>\n",
              "      <td>0.562647</td>\n",
              "      <td>0.772541</td>\n",
              "      <td>14:24</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9OjmSYikn6fu",
        "colab_type": "code",
        "outputId": "e4cb4feb-aa80-4fe5-dc33-8ca9b56669eb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 79
        }
      },
      "source": [
        "learn.freeze_to(-2)\n",
        "learn.fit_one_cycle(1, slice(5e-3/2., 5e-3))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>0.623170</td>\n",
              "      <td>0.531070</td>\n",
              "      <td>0.780738</td>\n",
              "      <td>14:33</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MUKGLOzAoARj",
        "colab_type": "code",
        "outputId": "867659d4-b81d-45a4-a136-27b0c972c0a8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 79
        }
      },
      "source": [
        "learn.unfreeze()\n",
        "learn.fit_one_cycle(1, slice(2e-3/100, 2e-3))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>0.581099</td>\n",
              "      <td>0.491195</td>\n",
              "      <td>0.803962</td>\n",
              "      <td>16:40</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TenH511JifiQ",
        "colab_type": "text"
      },
      "source": [
        "# Inference\n",
        "Nonw, let's play with the model we've just learned!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BAhX3D1JifiY",
        "colab_type": "code",
        "outputId": "35734812-ded1-4744-aa1d-ccc28cc0fcf2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "learn.predict(\"seriously would pay $30 a flight for seats that didn't have this playing.\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(Category negative, tensor(0), tensor([0.9379, 0.0568, 0.0052]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 127
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2cd7y0buKGy_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "64d08a70-5e1d-4aa8-ce4a-eb542655f38f"
      },
      "source": [
        "learn.predict(data_prep[data_prep.is_valid==True]['text'].iloc[14])"
      ],
      "execution_count": 161,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(Category positive, tensor(2), tensor([0.3009, 0.1566, 0.5425]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 161
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3BRLMNH7Jh2e",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3d9683d3-1c9f-48ca-c793-638ba6ebe21f"
      },
      "source": [
        "learn.predict(data_prep[data_prep.is_valid==True]['text'].iloc[9])"
      ],
      "execution_count": 150,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(Category neutral, tensor(1), tensor([0.2564, 0.6093, 0.1342]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 150
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zrRafu35ifio",
        "colab_type": "text"
      },
      "source": [
        "# Conclusions\n",
        "Lety's see the evollution of the accuracy when we increas the size of the train data.\n",
        "For each training size, we report the best accuracy among the different epochs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lg3O_WPH4sRO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predictions=[str((learn.predict(x))[0]) for x in data_prep[data_prep.is_valid==True]['text']]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ThwCCmgFIj5a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def returnLabel(x):\n",
        "  if x =='negative':\n",
        "    return 0\n",
        "  elif x=='neutral':\n",
        "    return 1\n",
        "  else:\n",
        "    return 2\n",
        "y_pred=[returnLabel(x) for x in predictions]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "in39uvlWKugf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_true=[returnLabel(x) for x in data_prep[data_prep.is_valid==True]['label']]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VvnZMgxv32aQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "4f779d2c-975a-4793-c445-076b4c033f3f"
      },
      "source": [
        "target_names = ['negative', 'neutral', 'positive']\n",
        "print(classification_report(y_true,y_pred,target_names=target_names))"
      ],
      "execution_count": 169,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.82      0.94      0.88      1836\n",
            "     neutral       0.72      0.51      0.60       620\n",
            "    positive       0.81      0.66      0.73       472\n",
            "\n",
            "    accuracy                           0.80      2928\n",
            "   macro avg       0.78      0.70      0.73      2928\n",
            "weighted avg       0.80      0.80      0.79      2928\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TulAyUmaK_Ws",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}